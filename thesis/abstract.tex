\begin{abstract}
  Spiking Neural Networks (SNNs) represent an emerging paradigm in machine learning, inspired by biological neurons, 
  with potential for greater energy efficiency compared to traditional Artificial Neural Networks (ANNs). Unlike ANNs, 
  which use continuous floating-point outputs, SNNs produce discrete (binary) spikes when a neuronâ€™s membrane voltage 
  exceeds a threshold.
  In this thesis we propose a novel firing model where neurons fire at multiple spiking levels (multi-bit spike trains) when 
  their membrane potentials reach corresponding thresholds. The project explores whether such models can enable more 
  efficient training or inference by facilitating higher communication bandwidth between neurons.
\end{abstract}
